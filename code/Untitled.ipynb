{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "29bac2bf",
   "metadata": {},
   "source": [
    "# Lung segmentation from Chest X-Ray dataset\n",
    "\n",
    "**About the data**:\n",
    "- The dataset is made up of images and segmentated mask from two diffrent sources.\n",
    "- There is a slight abnormality in naming convention of masks.\n",
    "- Some images don't have their corresponding masks.\n",
    "- Images from the Shenzhen dataset has apparently smaller lungs as compared to the Montgomery dataset.\n",
    "\n",
    "\n",
    "## Take a look at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3c4ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from cv2 import imread, createCLAHE \n",
    "import cv2\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_path = os.path.join(\"../input/data/Lung Segmentation/CXR_png\")\n",
    "mask_path = os.path.join(\"../input/data/Lung Segmentation/\",\"masks/\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a64ae041",
   "metadata": {},
   "source": [
    "\n",
    "They can inspected the concerning dataset seperately [here](http://https://www.kaggle.com/kmader/pulmonary-chest-xray-abnormalities/home)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c170965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 704 masks but 800 images. Hence we are going to\n",
    "# make a 1-1 correspondance from mask to images, not the usual other way.\n",
    "images = os.listdir(image_path)\n",
    "mask = os.listdir(mask_path)\n",
    "mask = [fName.split(\".png\")[0] for fName in mask]\n",
    "image_file_name = [fName.split(\"_mask\")[0] for fName in mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e32d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = [i for i in mask if \"mask\" in i]\n",
    "print(\"Total mask that has modified name:\",len(check))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "35510cf9",
   "metadata": {},
   "source": [
    "Earlier I was going to train on the Shenzhen dataset while perform prediction on the Montgomery dataset. However, the nature of the data was diffrent in both the set. The images from Shenzhen dataset had smaller lung-to-image ratio as compared to the Montgomery dataset.\n",
    "\n",
    "Thus, I am loading the two dataset seperately which I combined once I got to know about the disparity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed763c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_files = set(os.listdir(image_path)) & set(os.listdir(mask_path))\n",
    "training_files = check\n",
    "\n",
    "def getData(X_shape, flag = \"test\"):\n",
    "    im_array = []\n",
    "    mask_array = []\n",
    "    \n",
    "    if flag == \"test\":\n",
    "        for i in tqdm(testing_files): \n",
    "            im = cv2.resize(cv2.imread(os.path.join(image_path,i)),(X_shape,X_shape))[:,:,0]\n",
    "            mask = cv2.resize(cv2.imread(os.path.join(mask_path,i)),(X_shape,X_shape))[:,:,0]\n",
    "            \n",
    "            im_array.append(im)\n",
    "            mask_array.append(mask)\n",
    "        \n",
    "        return im_array,mask_array\n",
    "    \n",
    "    if flag == \"train\":\n",
    "        for i in tqdm(training_files): \n",
    "            im = cv2.resize(cv2.imread(os.path.join(image_path,i.split(\"_mask\")[0]+\".png\")),(X_shape,X_shape))[:,:,0]\n",
    "            mask = cv2.resize(cv2.imread(os.path.join(mask_path,i+\".png\")),(X_shape,X_shape))[:,:,0]\n",
    "\n",
    "            im_array.append(im)\n",
    "            mask_array.append(mask)\n",
    "\n",
    "        return im_array,mask_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becf1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform sanity check\n",
    "\n",
    "def plotMask(X,y):\n",
    "    sample = []\n",
    "    \n",
    "    for i in range(6):\n",
    "        left = X[i]\n",
    "        right = y[i]\n",
    "        combined = np.hstack((left,right))\n",
    "        sample.append(combined)\n",
    "        \n",
    "        \n",
    "    for i in range(0,6,3):\n",
    "\n",
    "        plt.figure(figsize=(25,10))\n",
    "        \n",
    "        plt.subplot(2,3,1+i)\n",
    "        plt.imshow(sample[i])\n",
    "        \n",
    "        plt.subplot(2,3,2+i)\n",
    "        plt.imshow(sample[i+1])\n",
    "        \n",
    "        \n",
    "        plt.subplot(2,3,3+i)\n",
    "        plt.imshow(sample[i+2])\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cde89c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "dim = 256*2\n",
    "X_train,y_train = getData(dim,flag=\"train\")\n",
    "X_test, y_test = getData(dim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ffe013e",
   "metadata": {},
   "source": [
    "# Perform Sanity Check\n",
    "\n",
    "It is prudent to perform sanity check of the data correspondance. It become a routine check-up after a while but it is very crucial to check if we had made a mistake in loading the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training set\")\n",
    "plotMask(X_train,y_train)\n",
    "print(\"testing set\")\n",
    "plotMask(X_test,y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74fabf56",
   "metadata": {},
   "source": [
    "Both the sets looks correct. Let's combine them and further use them as a unified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecedbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train).reshape(len(X_train),dim,dim,1)\n",
    "y_train = np.array(y_train).reshape(len(y_train),dim,dim,1)\n",
    "X_test = np.array(X_test).reshape(len(X_test),dim,dim,1)\n",
    "y_test = np.array(y_test).reshape(len(y_test),dim,dim,1)\n",
    "assert X_train.shape == y_train.shape\n",
    "assert X_test.shape == y_test.shape\n",
    "images = np.concatenate((X_train,X_test),axis=0)\n",
    "mask  = np.concatenate((y_train,y_test),axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de74e301",
   "metadata": {},
   "source": [
    "## Define  the network and callbacks\n",
    "\n",
    "I am going to use my favourite segmentation network - U-Nets. You can read about them [here](https://arxiv.org/abs/1505.04597)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f36788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras import backend as keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = keras.flatten(y_true)\n",
    "    y_pred_f = keras.flatten(y_pred)\n",
    "    intersection = keras.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def unet(input_size=(256,256,1)):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    return Model(inputs=[inputs], outputs=[conv10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20d222d5",
   "metadata": {},
   "source": [
    "#### Compile and train the Unet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc68fb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet(input_size=(512,512,1))\n",
    "model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss,\n",
    "                  metrics=[dice_coef, 'binary_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3165bac6",
   "metadata": {},
   "source": [
    "## Callbacks, Early Stopping and Reduced LR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452006b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_weights.best.hdf5\".format('cxr_reg')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min', save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n",
    "                                   patience=3, \n",
    "                                   verbose=1, mode='min', epsilon=0.0001, cooldown=2, min_lr=1e-6)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\", \n",
    "                      patience=15) # probably needs to be more patient, but kaggle time is limited\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "665dfa16",
   "metadata": {},
   "source": [
    "#### Train the model\n",
    "\n",
    "I intially used a 60-40 train-test spit and got a loss of -0.97. However, the better way to do it is 80-10-10 train-test-validation spit. Below I am roughly doing the later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from keras.optimizers import Adam \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model.compile(optimizer=Adam(lr=2e-4), \n",
    "              loss=[dice_coef_loss], \n",
    "           metrics = [dice_coef, 'binary_accuracy'])\n",
    "\n",
    "train_vol, validation_vol, train_seg, validation_seg = train_test_split((images-127.0)/127.0, \n",
    "                                                            (mask>127).astype(np.float32), \n",
    "                                                            test_size = 0.1,random_state = 2018)\n",
    "\n",
    "train_vol, test_vol, train_seg, test_seg = train_test_split(train_vol,train_seg, \n",
    "                                                            test_size = 0.1, \n",
    "                                                            random_state = 2018)\n",
    "\n",
    "loss_history = model.fit(x = train_vol,\n",
    "                       y = train_seg,\n",
    "                         batch_size = 16,\n",
    "                  epochs = 50,\n",
    "                  validation_data =(test_vol,test_seg) ,\n",
    "                  callbacks=callbacks_list)\n",
    "\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bda7c77",
   "metadata": {},
   "source": [
    "## Plot the metric and evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9526dd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "ax1.plot(loss_history.history['loss'], '-', label = 'Loss')\n",
    "ax1.plot(loss_history.history['val_loss'], '-', label = 'Validation Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(100*np.array(loss_history.history['binary_accuracy']), '-', \n",
    "         label = 'Accuracy')\n",
    "ax2.plot(100*np.array(loss_history.history['val_binary_accuracy']), '-',\n",
    "         label = 'Validation Accuracy')\n",
    "ax2.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae856349",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5ade44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_candidates = np.random.randint(1,validation_vol.shape[0],10)\n",
    "preds = model.predict(validation_vol)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for i in range(0,9,3):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    \n",
    "    plt.imshow(np.squeeze(validation_vol[pred_candidates[i]]))\n",
    "    plt.xlabel(\"Base Image\")\n",
    "    \n",
    "    \n",
    "    plt.subplot(3,3,i+2)\n",
    "    plt.imshow(np.squeeze(validation_seg[pred_candidates[i]]))\n",
    "    plt.xlabel(\"Mask\")\n",
    "    \n",
    "    plt.subplot(3,3,i+3)\n",
    "    plt.imshow(np.squeeze(preds[pred_candidates[i]]))\n",
    "    plt.xlabel(\"Pridiction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
